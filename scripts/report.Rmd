---
title: "Movielens Notebook"
output:
  pdf_document: default
  html_notebook: default
---

# Introduction
In this notebook, a recommendation system is built in order to help predict ratings for movies. The data set comes from the movielens data set. This data set that is used contains six variables which record the following information: movieId, userId, rating, date, title, and genre. Therefore, each records pertains to a review of a certain movie, done by a certain user in a specific time. Movie information (title and genre) is recorded in each record. The purpose of the analysis is to develop a recommendation system that will help predict ratings of different movies, therefore allowing the system to make recommendations to users.

To develop this system, the data was first inspected to identify the type of data that is stored, whether the data is clean, and whether there are missing values. The next step after that was to perform exploratory data analysis in order to develop a better understanding of what the data is telling us. This analysis motivates the development of the recommendation system. 

The development of the recommendation system was performed by taking into account variations in user taste, popularity of certain genres, and variations in the reviews of certain titles. 

# Method

Ideally, regression would be used in order to account for the effect of each independent variable on the dependent variable (the rating). However, given the size of the data set, it is not possible to use the lm() function. Therefore, we calculate the effect of each independent variable by calculating the average of the deviation of each rating within each category of the independent variable. In other words, we group by each independent variable, and calculate the distance of the average rating in each category from the overall average rating. This will allow us to calculate a coefficient for each level of the independent variables. This coefficient is then added to the overall average rating in order to produce our predictions. The next section shows how this is done.  

# Results

## Create the data
First, we create the data sets and load the libraries:

```{r}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")

library(tidyverse)
library(caret)
library(data.table)
library(lubridate)
library(ggplot2)
options(tinytex.verbose = TRUE)
# MovieLens 10M dataset:
# https://grouplens.org/datasets/movielens/10m/
# http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
colnames(movies) <- c("movieId", "title", "genres")

# if using R 4.0 or later:
movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(movieId),
                                           title = as.character(title),
                                           genres = as.character(genres))


movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding") 
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
edx <- movielens[-test_index,]
temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
  semi_join(edx, by = "movieId") %>%
  semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

## Exploratory analysis

Now, we take a look at the structure of the data:

```{r}
str(edx)
```
We note that there are five variables. Let us check to see if there are any null values:

```{r}
colSums(is.na(edx))
```
There are no null values. Let us take a look at the primary variable of importance, the rating:

```{r}
summary(edx$rating)
```
We see that the median rating is 4, which is quite high. To see the distribution of the ratings, we look at the histogram:

```{r}
ggplot(edx) + geom_histogram(aes(rating), color = "black")
```
The histogram shows that the ratings tend to be high, with the majority being between 3 and 5. 

Do all movies appear the same number of times? Or is it that some movies are rated many times while other movies receive ratings a small number of time? To investigate this, we look at another histogram:

```{r}
edx %>% count(movieId) %>% ggplot() + 
  geom_histogram(aes(n), bins = 30, color = "black") + 
  scale_x_log10()
```
The figure clearly shows that there is variation in the number of times that movies appear. This indicates that we might need to use regularization in order to account for this variation. The same can be said about the number of users who leave a rating at shown by the figure produced by the following code:

```{r}
edx %>% count(userId) %>% ggplot() + 
  geom_histogram(aes(n), bins = 30, color = "black") + 
  scale_x_log10()
```
The same figure is produced for the genres:

```{r}
edx %>% count(genres) %>% ggplot() + 
  geom_histogram(aes(n)) + scale_x_log10()
```
From all the above, we see that there is variation. Some movies appear a few times while some appear a lot. Same applies to users and genres.

## Building the models
Now that we have a general idea about the nature of the data, we can start building the recommendation system. Girst however, we need to define the function that will calculate the RMSE in order to evaluate the recommendation systems:

```{r}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```
### Naive model

The simplest model is the one that predicts the ratings simply as the average:

```{r}
mu <- mean(edx$rating)
naive_rmse <- RMSE(validation$rating, mu)
naive_rmse
rmse_results <- data.frame(method = "Just the average", RMSE = naive_rmse)
print("The RMSE for the naive model is: ")
naive_rmse
```
### Genres effects

We now incorporate the effect of the genres. This is done by calculating the mean deviation of each genres from the overall mean:

```{r}
genres_avgs <- edx %>% group_by(genres) %>% summarize(b_g = mean(rating - mu))
predicted_ratings <- mu + validation %>% 
  left_join(genres_avgs, by = "genres") %>% 
  pull(b_g)
genres_rmse <- RMSE(predicted_ratings, validation$rating)
rmse_results <- rmse_results %>% 
  add_row(method = "Genres effect", RMSE = genres_rmse)
```
The RMSE table now looks like this:

```{r}
rmse_results
```
We see that there is a drop in the RMSE. This means that the genre account for a lot of the variability in the rating. Certain genres tend to be rated more than other genres. The following shows the highest rated genres:

```{r}
edx %>% group_by(genres) %>% summarise(rating = mean(rating)) %>% arrange(desc(rating)) %>% slice(1:10)
```
The following shows the lowest rated genres:

```{r}
edx %>% group_by(genres) %>% summarise(rating = mean(rating)) %>% arrange(rating) %>% slice(1:10)
```

### Movie effects

We now look at the coefficients, or effects, of the movie ID. This is because, perhaps some movies tend to be rated different than other movies by all users:

```{r}
movie_avgs <- edx %>% group_by(movieId) %>% summarize(b_i = mean(rating - mu))
predicted_ratings <- mu + validation %>% 
  left_join(movie_avgs, by = "movieId") %>% 
  pull(b_i)
movie_rmse <- RMSE(predicted_ratings, validation$rating)

rmse_results <- rmse_results %>% 
  add_row(method = "Movie effect", RMSE = movie_rmse)
rmse_results
```

### User effects

We now do the same for the users, since some users might be more positive with their reviews than others:

```{r}
user_avgs <- edx %>% group_by(userId) %>% summarize(b_u = mean(rating - mu))
predicted_ratings <- mu + validation %>% 
  left_join(user_avgs, by = "userId") %>% 
  pull(b_u)
user_rmse <- RMSE(predicted_ratings, validation$rating)

rmse_results <- rmse_results %>% 
  add_row(method = "User effect", RMSE = user_rmse)
rmse_results
```
We see that there is a drop in the RMSE when we add the genres effect, movies effect, or the user effect.

### User and movie effects together

We next include both movie effects and uder effects at the same time:

```{r}
user_avgs <- edx %>% left_join(movie_avgs, by = "movieId") %>% 
  group_by(userId) %>% summarise(b_u = mean(rating - mu - b_i))
predicted_ratings <- validation %>% 
  left_join(movie_avgs, by = "movieId") %>% 
  left_join(user_avgs, by = "userId") %>% 
  mutate(pred = mu + b_i + b_u) %>% pull(pred)
usermovie_rmse <- RMSE(predicted_ratings, validation$rating)

rmse_results <- rmse_results %>% 
  add_row(method = "User and movie effect", RMSE = usermovie_rmse)
rmse_results
```
The RMSE obtained by this model is the lowest so far.

### Regularization

It was noted previously that some movies, users, and genres, appear more than others. This means that in some cases, a small number of appearences might produce an average that is not reliable. In order to penalise such instances, regularization is used. In order to obtain the optimal lambda parameter that is to be used, the model including all three effects (movies, users, and genres) is run many times, each time using a different value of lambda. The RMSE of all models are compared, and the lambda value that produces the lowest value of RMSE is chosen:

```{r}
lambdas <- seq(0, 10, 0.25)

rmses <- sapply(lambdas, function(l){
  b_i <- edx %>% group_by(movieId) %>% 
    summarise(b_i = sum(rating - mu)/(n() + l))
  
  b_u <- edx %>% left_join(b_i, by = "movieId") %>% 
    group_by(userId) %>% 
    summarise(b_u = sum(rating - b_i - mu)/(n() + l))
  
  b_g <- edx %>% left_join(b_i, by = "movieId") %>% 
    left_join(b_u, by = "userId") %>% group_by(genres) %>% 
    summarise(b_g = sum(rating - b_i - b_u - mu)/(n() + l))
  
  predicted_ratings <- validation %>% 
    left_join(b_i, by = "movieId") %>% 
    left_join(b_u, by = "userId") %>% 
    left_join(b_g, by = "genres") %>% 
    mutate(pred = mu + b_i + b_u + b_g) %>% 
    pull(pred)
  
  return(RMSE(predicted_ratings, validation$rating))
})
qplot(lambdas, rmses)
```
We see that a lambda of five produces the lowest RMSE. We therefore save this value of lambda and add the RMSE value to our results table:

```{r}
lambda <- lambdas[which.min(rmses)]
rmse_results <- rmse_results %>% 
  add_row(method = "User, movie, and genres reg.", RMSE = min(rmses))
rmse_results

```
The results table clearly shows that regularization, when including the effects of movies, users, and genres, results in the lowest RMSE.

We save the coefficients obtained for this specific lambda value so we do not have to repeat the above simulation:

```{r}
b_i <- edx %>% group_by(movieId) %>% 
  summarise(b_i = sum(rating - mu)/(n() + lambda))

b_u <- edx %>% left_join(b_i, by = "movieId") %>% 
  group_by(userId) %>% 
  summarise(b_u = sum(rating - b_i - mu)/(n() + lambda))

b_g <- edx %>% left_join(b_i, by = "movieId") %>% 
  left_join(b_u, by = "userId") %>% group_by(genres) %>% 
  summarise(b_g = sum(rating - b_i - b_u - mu)/(n() + lambda))
```
### Including the date

Another variable included in the data set is the timestamp of the rating. Perhaps reviewing a movie in a certain day would increase (or decrease) the rating that is provided? In order to see whether movie ratings varied according to date, a graph can be produced:

```{r}
edx %>% mutate(date = as_datetime(timestamp)) %>%
  mutate(week = week(date)) %>% group_by(week) %>% 
  summarise(rating = mean(rating)) %>% ggplot() + 
  geom_point(aes(week, rating))
```

The graph clearly shows that when the ratings are given at the end of the year, they tend to be higher than the ratings given in the first months of the year. This indicates that the date might have an effect on the rating. We therefore try to account for this effect:

```{r}
b_w <- edx %>% left_join(b_i, by = "movieId") %>% 
  left_join(b_u, by = "userId") %>% 
  left_join(b_g, by = "genres") %>% 
  mutate(date = as_datetime(timestamp)) %>%
  mutate(week = week(date)) %>% group_by(week) %>% 
  summarise(b_w = mean(rating - b_g - b_u - b_i - mu))

predicted_ratings <- validation %>%
  mutate(date = as_datetime(timestamp)) %>%
  mutate(week = week(date)) %>% 
  left_join(b_i, by = "movieId") %>% 
  left_join(b_u, by = "userId") %>% 
  left_join(b_g, by = "genres") %>% 
  left_join(b_w, by = "week") %>% 
  mutate(pred = mu + b_i + b_u + b_g + b_w) %>% 
  pull(pred)
rmse <- RMSE(predicted_ratings, validation$rating)
rmse_results <- rmse_results %>% 
  add_row(method = "User, movie, genres reg. with date", RMSE = rmse)
rmse_results
```

We see that accounting for the effect of the date results in a drop in the RMSE.

# Conclusion

This report presented an analysis of the movielens data set. The report displays the results obtained while attempting to build a movie recommendation system.

The analysis revealed that the rating achieved by a movie is affected by the movie title, the user providing the rating, the genres included in the movie, and the date (or week of the year) that the rating was given. The analysis revealed that once these variables are accounted for, it is possible to produce a fairly reliable movie recommendation system with an RMSE value that is less than 0.865.

The model developed is not without its limitations. Although the overall RMSE is acceptable, this does not mean that the model is predicting with equal accuracy the ratings of all titles, or the ratings of all users. It might be the case that the model does well overall, but that in specific cases it is much worse. Therefore, future work should investigate whether such cases of large values of errors exist, and what can be done in order to reduce these errors.  
